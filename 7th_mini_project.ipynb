{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7TH Mini Project Selected Topics\n",
    "- Name : Youssef Ayman \n",
    "- Regnum : 211000348\n",
    "- Name : Adham Bahnasy\n",
    "- Regnum : 211000117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Nessesary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, T5Tokenizer, T5ForConditionalGeneration, BartTokenizer, BartForConditionalGeneration\n",
    "from rouge import Rouge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the models and tokenizers\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model Architecture:\n",
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Display BERTSUM (BERT) Model Architecture\n",
    "print(\"BERT Model Architecture:\")\n",
    "print(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T5 Model Architecture:\n",
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Display T5 Model Architecture\n",
    "print(\"\\nT5 Model Architecture:\")\n",
    "print(t5_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BART Model Architecture:\n",
      "BartForConditionalGeneration(\n",
      "  (model): BartModel(\n",
      "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
      "    (encoder): BartEncoder(\n",
      "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x BartEncoderLayer(\n",
      "          (self_attn): BartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): BartDecoder(\n",
      "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x BartDecoderLayer(\n",
      "          (self_attn): BartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Display BART Model Architecture\n",
    "print(\"\\nBART Model Architecture:\")\n",
    "print(bart_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTSUM (Extractive Summarization)\n",
    "def bertsum_summarize(text):\n",
    "    inputs = bert_tokenizer.encode(\"[CLS] \" + text + \" [SEP]\", return_tensors='pt')\n",
    "    outputs = bert_model(inputs)\n",
    "    logits = outputs.logits\n",
    "    summary = bert_tokenizer.decode(inputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# T5 (Abstractive Summarization)\n",
    "def t5_summarize(text):\n",
    "    inputs = t5_tokenizer.encode(\"summarize: \" + text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    summary_ids = t5_model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# BART (Abstractive Summarization)\n",
    "def bart_summarize(text):\n",
    "    inputs = bart_tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    summary_ids = bart_model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "input_text = \"Climate change has become one of the most pressing issues of our time, impacting ecosystems, economies, and communities worldwide. Due to increasing greenhouse gas emissions, primarily from burning fossil fuels like coal, oil, and natural gas, global temperatures are rising at an unprecedented rate. This warming trend has led to a multitude of environmental changes, including more frequent and severe weather events like hurricanes, droughts, and wildfires. The melting of polar ice caps and glaciers is causing sea levels to rise, which threatens coastal cities and small island nations. Additionally, climate change is disrupting natural habitats, leading to shifts in species distribution and behavior, and even contributing to the endangerment of certain species. In response, many countries have committed to reducing their carbon footprint by implementing renewable energy sources, enhancing energy efficiency, and promoting sustainable practices. However, despite these efforts, scientists warn that without more aggressive and immediate action, the impacts of climate change will become increasingly difficult to manage, with profound consequences for future generations.\"\n",
    "\n",
    "# Summarize the input text using each model\n",
    "bertsum_summary = bertsum_summarize(input_text)\n",
    "t5_summary = t5_summarize(input_text)\n",
    "bart_summary = bart_summarize(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mBERTSUM Summary:\n",
      "\u001b[0m\n",
      "climate change has become one of the most pressing issues of our time, impacting ecosystems, economies, and communities worldwide\n",
      "due to increasing greenhouse gas emissions, primarily from burning fossil fuels like coal, oil, and natural gas, global temperatures are rising at an unprecedented rate\n",
      "this warming trend has led to a multitude of environmental changes, including more frequent and severe weather events like hurricanes, droughts, and wildfires\n",
      "the melting of polar ice caps and glaciers is causing sea levels to rise, which threatens coastal cities and small island nations\n",
      "additionally, climate change is disrupting natural habitats, leading to shifts in species distribution and behavior, and even contributing to the endangerment of certain species\n",
      "in response, many countries have committed to reducing their carbon footprint by implementing renewable energy sources, enhancing energy efficiency, and promoting sustainable practices\n",
      "however, despite these efforts, scientists warn that without more aggressive and immediate action, the impacts of climate change will become increasingly difficult to manage, with profound consequences for future generations.\n",
      "\n",
      "==================================================\n",
      "\n",
      "\u001b[1m\u001b[92mT5 Summary:\n",
      "\u001b[0m\n",
      "global temperatures are rising at an unprecedented rate due to increasing greenhouse gas emissions\n",
      "melting of polar ice caps and glaciers is causing sea levels to rise, which threatens coastal cities and small island nations\n",
      "climate change disrupting natural habitats, leading to shifts in species distribution and behavior.\n",
      "\n",
      "==================================================\n",
      "\n",
      "\u001b[1m\u001b[92mBART Summary:\n",
      "\u001b[0m\n",
      "Climate change has become one of the most pressing issues of our time\n",
      "Due to increasing greenhouse gas emissions, global temperatures are rising at an unprecedented rate\n",
      "In response, many countries have committed to reducing their carbon footprint.\n"
     ]
    }
   ],
   "source": [
    "# Print the summaries\n",
    "print(\"\\033[1m\\033[92m\" + \"BERTSUM Summary:\\n\" + \"\\033[0m\")\n",
    "for sentence in bertsum_summary.split('. '):\n",
    "    print(sentence)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\\033[92m\" + \"T5 Summary:\\n\" + \"\\033[0m\")\n",
    "for sentence in t5_summary.split('. '):\n",
    "    print(sentence)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\\033[92m\" + \"BART Summary:\\n\" + \"\\033[0m\")\n",
    "for sentence in bart_summary.split('. '):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Rouge and Average Rouge for all models and Compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mBERTSUM ROUGE Scores:\n",
      "\u001b[0m\n",
      "{'rouge-1': {'r': 0.9473684210526315, 'p': 0.9692307692307692, 'f': 0.9581748999436164}, 'rouge-2': {'r': 0.9207317073170732, 'p': 0.9263803680981595, 'f': 0.9235473956116675}, 'rouge-l': {'r': 0.9473684210526315, 'p': 0.9692307692307692, 'f': 0.9581748999436164}}\n",
      "\n",
      "==================================================\n",
      "\n",
      "\u001b[1m\u001b[92mT5 ROUGE Scores:\n",
      "\u001b[0m\n",
      "{'rouge-1': {'r': 0.3082706766917293, 'p': 0.9318181818181818, 'f': 0.46327683242235634}, 'rouge-2': {'r': 0.24390243902439024, 'p': 0.851063829787234, 'f': 0.379146915968644}, 'rouge-l': {'r': 0.2857142857142857, 'p': 0.8636363636363636, 'f': 0.42937852733761056}}\n",
      "\n",
      "==================================================\n",
      "\n",
      "\u001b[1m\u001b[92mBART ROUGE Scores:\n",
      "\u001b[0m\n",
      "{'rouge-1': {'r': 0.2631578947368421, 'p': 0.9722222222222222, 'f': 0.41420118007912893}, 'rouge-2': {'r': 0.20121951219512196, 'p': 0.8918918918918919, 'f': 0.3283582059513379}, 'rouge-l': {'r': 0.2631578947368421, 'p': 0.9722222222222222, 'f': 0.41420118007912893}}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ROUGE scores for each model\n",
    "bertsum_scores = rouge.get_scores(bertsum_summary, input_text)\n",
    "t5_scores = rouge.get_scores(t5_summary, input_text)\n",
    "bart_scores = rouge.get_scores(bart_summary, input_text)\n",
    "\n",
    "print(\"\\033[1m\\033[92m\" + \"BERTSUM ROUGE Scores:\\n\" + \"\\033[0m\")\n",
    "print(bertsum_scores[0])\n",
    "# r is the recall of the model, p is the precision of the model, and f is the F1 score of the model.\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\\033[92m\" + \"T5 ROUGE Scores:\\n\" + \"\\033[0m\")\n",
    "print(t5_scores[0])\n",
    "# r is the recall of the model, p is the precision of the model, and f is the F1 score of the model.\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\\033[92m\" + \"BART ROUGE Scores:\\n\" + \"\\033[0m\")\n",
    "print(bart_scores[0])\n",
    "# r is the recall of the model, p is the precision of the model, and f is the F1 score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mBERTSUM Average ROUGE Scores:\n",
      "\u001b[0m\n",
      "{'rouge-1': 0.9582580300756725, 'rouge-2': 0.9235531570089668, 'rouge-l': 0.9582580300756725}\n",
      "\n",
      "==================================================\n",
      "\n",
      "\u001b[1m\u001b[92mT5 Average ROUGE Scores:\n",
      "\u001b[0m\n",
      "{'rouge-1': 0.5677885636440891, 'rouge-2': 0.4913710615934228, 'rouge-l': 0.5262430588960866}\n",
      "\n",
      "==================================================\n",
      "\n",
      "\u001b[1m\u001b[92mBART Average ROUGE Scores:\n",
      "\u001b[0m\n",
      "{'rouge-1': 0.5498604323460644, 'rouge-2': 0.4738232033461172, 'rouge-l': 0.5498604323460644}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average ROUGE scores for each model\n",
    "# N.T : 3 is the number of metrics (recall, precision, F1 score) in ROUGE evaluation\n",
    "bertsum_avg_rouge = {key: sum([bertsum_scores[0][key][metric] for metric in bertsum_scores[0][key]]) / 3 for key in bertsum_scores[0].keys()}\n",
    "t5_avg_rouge = {key: sum([t5_scores[0][key][metric] for metric in t5_scores[0][key]]) / 3 for key in t5_scores[0].keys()} \n",
    "bart_avg_rouge = {key: sum([bart_scores[0][key][metric] for metric in bart_scores[0][key]]) / 3 for key in bart_scores[0].keys()}\n",
    "\n",
    "# Print the average ROUGE scores for each model\n",
    "print(\"\\033[1m\\033[92m\" + \"BERTSUM Average ROUGE Scores:\\n\" + \"\\033[0m\")\n",
    "print(bertsum_avg_rouge)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\\033[92m\" + \"T5 Average ROUGE Scores:\\n\" + \"\\033[0m\")\n",
    "print(t5_avg_rouge)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\\033[92m\" + \"BART Average ROUGE Scores:\\n\" + \"\\033[0m\")\n",
    "print(bart_avg_rouge)\n",
    "\n",
    "# N.T : if rouge_score > 0.5 then the model is good at summarization task else it is not good at summarization task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│                                           Comparison of Text Summarization Models                                                               │\n",
      "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│                      **BERTSUM**                            **T5**                              **BART**                                        │\n",
      "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│  **Input Format**                                                                                                                               │\n",
      "│      - BERTSUM: Tokenized text with special tokens `[CLS]` and `[SEP]` to denote the start of the document and end of each sentence.            │\n",
      "│      - T5: Text in the format `summarize: <text>`.                                                                                              │\n",
      "│      - BART: Plain text without special tokens, offering flexibility in input format.                                                           │\n",
      "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│  **Architecture**                                                                                                                               │\n",
      "│      - BERTSUM: Base model is BERT with inter-sentence Transformer layers on top of BERT, and a classifier layer for sentence importance.       │\n",
      "│      - T5: Encoder-decoder architecture based on Transformer, pre-trained on a diverse set of text-to-text tasks.                               │\n",
      "│      - BART: Encoder-decoder Transformer pre-trained with a denoising autoencoder objective to enhance text generation.                         │\n",
      "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│  **Performance Metrics (ROUGE Scores)**                                                                                                         │\n",
      "│      - ROUGE-1: 0.96                               |  ROUGE-1: 0.57                                |  ROUGE-1: 0.55                             │\n",
      "│      - ROUGE-2: 0.92                               |  ROUGE-2: 0.49                                |  ROUGE-2: 0.47                             │\n",
      "│      - ROUGE-L: 0.96                               |  ROUGE-L: 0.53                                |  ROUGE-L: 0.55                             │\n",
      "└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparison of Models\n",
    "\n",
    "comparison = f\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
    "│                                           Comparison of Text Summarization Models                                                               │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│                      **BERTSUM**                            **T5**                              **BART**                                        │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│  **Input Format**                                                                                                                               │\n",
    "│      - BERTSUM: Tokenized text with special tokens `[CLS]` and `[SEP]` to denote the start of the document and end of each sentence.            │\n",
    "│      - T5: Text in the format `summarize: <text>`.                                                                                              │\n",
    "│      - BART: Plain text without special tokens, offering flexibility in input format.                                                           │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│  **Architecture**                                                                                                                               │\n",
    "│      - BERTSUM: Base model is BERT with inter-sentence Transformer layers on top of BERT, and a classifier layer for sentence importance.       │\n",
    "│      - T5: Encoder-decoder architecture based on Transformer, pre-trained on a diverse set of text-to-text tasks.                               │\n",
    "│      - BART: Encoder-decoder Transformer pre-trained with a denoising autoencoder objective to enhance text generation.                         │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│  **Performance Metrics (ROUGE Scores)**                                                                                                         │\n",
    "│      - ROUGE-1: {bertsum_avg_rouge['rouge-1']:.2f}                               |  ROUGE-1: {t5_avg_rouge['rouge-1']:.2f}                                |  ROUGE-1: {bart_avg_rouge['rouge-1']:.2f}                             │\n",
    "│      - ROUGE-2: {bertsum_avg_rouge['rouge-2']:.2f}                               |  ROUGE-2: {t5_avg_rouge['rouge-2']:.2f}                                |  ROUGE-2: {bart_avg_rouge['rouge-2']:.2f}                             │\n",
    "│      - ROUGE-L: {bertsum_avg_rouge['rouge-l']:.2f}                               |  ROUGE-L: {t5_avg_rouge['rouge-l']:.2f}                                |  ROUGE-L: {bart_avg_rouge['rouge-l']:.2f}                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\"\n",
    "\n",
    "print(comparison)\n",
    "# N.T : if rouge_score > 0.5 then the model is good at summarization task else it is not good at summarization task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization Models: Architecture and Performance Comparison\n",
    "\n",
    "## Overview\n",
    "\n",
    "This document provides a comparison of three text summarization models: BERTSUM, T5, and BART. Each model is evaluated based on its input format, architecture, and performance metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Input Format\n",
    "\n",
    "| Model      | Input Format                                                                                               |\n",
    "|------------|------------------------------------------------------------------------------------------------------------|\n",
    "| **BERTSUM** | Tokenized text with special tokens `[CLS]` and `[SEP]` to denote the beginning and end of each sentence.  |\n",
    "| **T5**       | Text in the format `summarize: <text>`, where `summarize:` is a prompt prefix for the task.              |\n",
    "| **BART**     | Plain text without additional tokens, allowing free-form input for generation tasks.                     |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Model Architecture\n",
    "\n",
    "| Model      | Architecture                                                                                               |\n",
    "|------------|------------------------------------------------------------------------------------------------------------|\n",
    "| **BERTSUM** | - **Base Model:** BERT model with added inter-sentence Transformer layers for improved summarization.     |\n",
    "|              | - **Additional Layers:** Transformer layers for sentence relationships and a classifier for sentence importance. |\n",
    "| **T5**       | - **Base Model:** Transformer encoder-decoder architecture.                                              |\n",
    "|              | - **Additional Layers:** Encoder-decoder design, pre-trained on various text-to-text tasks.               |\n",
    "| **BART**     | - **Base Model:** Transformer encoder-decoder architecture, with denoising autoencoder pre-training.      |\n",
    "|              | - **Additional Layers:** Similar encoder-decoder layers, optimized for text generation tasks.             |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Performance Metrics\n",
    "\n",
    "The performance of each model is evaluated using ROUGE scores, which measure the quality of summaries by comparing them to reference summaries.\n",
    "\n",
    "| Model       | ROUGE-1 | ROUGE-2 | ROUGE-L |\n",
    "|-------------|---------|---------|---------|\n",
    "| **BERTSUM** | 0.96    | 0.92    | 0.96    |\n",
    "| **T5**      | 0.57    | 0.49    | 0.53    |\n",
    "| **BART**    | 0.55    | 0.47    | 0.55    |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Findings\n",
    "\n",
    "- **BERTSUM** outperforms T5 and BART across all ROUGE metrics, likely due to its specialized inter-sentence layers designed for capturing sentence relationships.\n",
    "- **T5** and **BART**, both encoder-decoder architectures, are versatile for various text generation tasks but perform slightly lower than BERTSUM in ROUGE metrics, potentially due to their more generalized pre-training objectives, But as for the output **BERTSUM** is not as accurate as **T5** and **BART**  in summerization for the end-user\n",
    "\n",
    "---\n",
    "\n",
    "This comparison highlights the strengths and limitations of each model for text summarization, with BERTSUM being the most accurate in ROUGE-based evaluations, and T5 and BART offering flexibility across text generation tasks.\n",
    "\n",
    "\n",
    "N.T : All Details are in  the Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Links \n",
    "- https://huggingface.co/google-bert/bert-base-uncased/blob/main/README.md\n",
    "- https://huggingface.co/google-t5/t5-small\n",
    "- https://huggingface.co/facebook/bart-large-cnn\n",
    "\n",
    "# Other links\n",
    "- https://jmlr.org/papers/volume21/20-074/20-074.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
